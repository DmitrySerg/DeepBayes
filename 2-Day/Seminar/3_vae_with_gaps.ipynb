{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Вариационный автокодировщик\n",
    "\n",
    "tl;dr: Вместо тождественного отображения вариационны автокодировщик выучивает вероятностую модель данных. Стохастическия вычисления и априорное распределение кодов дополнительно регуляризуют модель."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import theano\n",
    "import theano.tensor as T\n",
    "import lasagne\n",
    "\n",
    "import matplotlib.pylab as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from utils import load_dataset, iterate_minibatches\n",
    "from theano.sandbox.rng_mrg import MRG_RandomStreams as RandomStreams\n",
    "\n",
    "BATCH_SIZE = 20\n",
    "HIDDEN_DIM = 2\n",
    "\n",
    "num_epochs = 10\n",
    "\n",
    "X_train, y_train, X_val, y_val, X_test, y_test = load_dataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Кратко о вариационных автокодировщиках\n",
    "\n",
    "Рассмотрим вариационный автокодировщик для бинарных наблюдений. Вариационный автокодировщик состоит из генеративной модели наблюдений\n",
    "\n",
    "\\begin{align}\n",
    "& p(x, z | \\theta) = p(x | z, \\theta) p(z) \\\\\n",
    "& p(x | z, \\theta) = \\prod_{i = 1}^D p_i(z, \\theta)^{x_i} (1 - p_i(z, \\theta))^{1 - x_i} \\\\\n",
    "& p(z) = \\mathcal N(z | 0, I)\n",
    "\\end{align}\n",
    "\n",
    "и приближенного апостериорного распределения\n",
    "\n",
    "\\begin{equation}\n",
    "q(z | x, \\phi) = \\mathcal N(z | \\mu(x, \\phi), \\operatorname{diag}(\\sigma^2(x, \\phi)))\n",
    "\\end{equation}\n",
    "\n",
    "Для краткости все выкладки приводятся для одного наблюдения $x$, параметры распределений по возможности опускаются. Для набора данных при обучении используется среднее значение нижней оценки. Цель обучения - максимизировать нижнюю оценку на обоснованность\n",
    "\n",
    "$$ \\mathcal L(x, \\theta, \\phi) = \\mathbb E_{q(z | x, \\phi)} p(x | z, \\theta) - \\operatorname{KL}(q(z | x, \\phi) || p(z )) = \\mathbb E_{q(z | x, \\phi)} \\log \\frac{p(x | z, \\phi)p(z)}{q(z | x, \\theta)} \\rightarrow \\max_{\\theta, \\phi} $$\n",
    "\n",
    "Как было рассказано на лекции, на практике нижняя оценка приближается оценкой \n",
    "\n",
    "\\begin{align*}\n",
    "&\\frac{1}{K} \\sum_{k=1}^K \\log \\frac{p(x | z_k)p(z_k)}{q(z_k | x)} \\\\\n",
    "& \\\\\n",
    "&z_k = \\mu(x, \\phi) + \\sigma^2(x, \\phi)^T \\varepsilon_k \\\\\n",
    "&\\varepsilon_k \\sim \\mathcal N(0, I), iid\n",
    "\\end{align*}\n",
    "\n",
    "с K=1, а затем максимизируется с помощью градиентного подъема.\n",
    "\n",
    "## Как это реализовать?\n",
    "\n",
    "Для вычисления приведенной выше нижней оценки необходимо уметь:\n",
    "1. Вычислять логарифм плотности всех распределений ($p(x | z)$, $p(z)$, $q(z | x)$)\n",
    "2. Сэмплировать из $q(z | x)$\n",
    "\n",
    "Следуя практике *tensorflow.distributions*, мы реализуем распределения как два класса с методами *log_prob()* и *sample()*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class BinaryVector():\n",
    "    def __init__(self, logits, rng=None):\n",
    "        self.rng = rng if rng else RandomStreams(lasagne.random.get_rng().randint(1,2147462579))\n",
    "        self.logits = logits\n",
    "\n",
    "    def log_prob(self, x):\n",
    "        # возвращает вектор вероятностей для каждого объекта в батче\n",
    "        pixelwise_log_probs = (\n",
    "            x * (self.logits - T.nnet.softplus(self.logits))\n",
    "            - (1 - x) * T.nnet.softplus(self.logits)\n",
    "        )\n",
    "        return T.sum(pixelwise_log_probs, axis=(1, 2, 3))\n",
    "    \n",
    "    def sample(self):\n",
    "        shape = self.logits.shape\n",
    "        return T.nnet.sigmoid(self.logits) >= self.rng.uniform(shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class MultivariateNormalDiag():\n",
    "    def __init__(self, loc=None, scale=None, rng=None):\n",
    "        self.rng = rng if rng else RandomStreams(lasagne.random.get_rng().randint(1,2147462579))\n",
    "        self.loc= loc\n",
    "        self.scale = scale\n",
    "    \n",
    "    def log_prob(self, z):\n",
    "        normalization_constant = (\n",
    "            - 0.5 * np.log(2 * np.pi)\n",
    "            - T.log(self.scale)\n",
    "        )\n",
    "        square_term = -0.5 * ((z - self.loc) / self.scale) ** 2\n",
    "        log_prob_vec = normalization_constant + square_term\n",
    "        return T.sum(log_prob_vec, axis=1)\n",
    "    \n",
    "    def sample(self):\n",
    "        ######################################################################\n",
    "        # Сэмплирование из q(z | x) - ключевой момент в вариационном автокоидровщике #\n",
    "        # Пользуясь методом self.rng.normal() реализуйте её самостоятельно         #\n",
    "        ######################################################################\n",
    "        return z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для параметров распределений построим две сети. Обратите внимание, что кодировщик теперь возвращает и код, и параметр масштаба"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def vae_encoder_mlp(input_x):\n",
    "    l_in = lasagne.layers.InputLayer(shape=(None, 1, 28, 28),\n",
    "                                     input_var=input_x)\n",
    "    ######################################################################################\n",
    "    # Реализуйте некоторую несложную архитектуру кодировщика, возвращающую вектор среднего и вектор #\n",
    "    # стандартных отклонений. Их размерность должны быть HIDDEN_DIM. Какие функции активаций ну-#\n",
    "    # жно использовать?                                                                    #\n",
    "    ######################################################################################\n",
    "    return l_out_loc, l_out_scale\n",
    "\n",
    "def vae_decoder_mlp(input_z):\n",
    "    l_in = lasagne.layers.InputLayer(shape=(None, 2),\n",
    "                                     input_var=input_z)\n",
    "    l_hid1 = lasagne.layers.DenseLayer(\n",
    "            l_in, num_units=64,\n",
    "            nonlinearity=lasagne.nonlinearities.rectify,\n",
    "            W=lasagne.init.GlorotUniform(),\n",
    "            name='d_hid1')\n",
    "    l_hid2 = lasagne.layers.DenseLayer(\n",
    "            l_hid1, num_units=128,\n",
    "            nonlinearity=lasagne.nonlinearities.rectify,\n",
    "            name='d_hid2')\n",
    "    l_out = lasagne.layers.DenseLayer(\n",
    "            l_hid2, num_units=28 ** 2,\n",
    "            nonlinearity=None,\n",
    "            name='d_out')\n",
    "    l_out = lasagne.layers.ReshapeLayer(l_out, shape=(-1, 1, 28, 28))\n",
    "    return l_out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Строим граф вычислений \n",
    "\n",
    "Входы и модель вывода $q(z | x)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_x = T.tensor4('inputs')\n",
    "#####################################################\n",
    "# Определите encoder_mean, encoder scale, затем      #\n",
    "# определите объект для апостериорного распределения qz_x  #\n",
    "####################################################\n",
    "\n",
    "encoder_mean, encoder_scale = # ... \n",
    "qz_x = # MultivariateNormalDiag ... "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Генеративная модель $p(x, z)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###################################################################\n",
    "# Определите параметр p(x | z) decoder_logits, затем                #\n",
    "# определите объекты pz распределения p(z) и px_z распределения p(x | z) #\n",
    "###################################################################\n",
    "\n",
    "decoder_logits = # vae_decoder_mlp \n",
    "pz = # MultivariateNormalDiag ...\n",
    "px_z = # BinaryVector ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ELBO и правила для обновления весов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "########################################################################################\n",
    "# Пользуясь методами px_z, p_z, qz_x определите функцию потерь для вариационного автокодировщика #\n",
    "# При обучении значение функции потерь должно принимать значения порядка -100 (от -150 и выше)   #\n",
    "# Создайте список параметров сети для передачи в оптимизатор                                  #\n",
    "# Что использовать в качестве функции потерь?                                               #\n",
    "elbo = None\n",
    "params = None\n",
    "loss = None\n",
    "########################################################################################\n",
    "updates = lasagne.updates.adam(loss, params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Определяем функции"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = theano.function(\n",
    "    [input_x],\n",
    "    elbo,\n",
    "    updates=updates\n",
    ")\n",
    "\n",
    "elbo_at_test = theano.function(\n",
    "    [input_x],\n",
    "    elbo\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "И обучаем модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    train_elbo = 0\n",
    "    train_batches = 0\n",
    "    start_time = time.time()\n",
    "    for batch in iterate_minibatches(X_train, batchsize=BATCH_SIZE):\n",
    "        \"\"\"\n",
    "        Обратите внимание, что тут предложенна вероятностная модель для бинарных данных.\n",
    "        MNIST содержит черно-белые изображения с градациями серого.\n",
    "        На практике при обучении автокодировщика получают бинарные данные, всякий раз положив случайно значение пикселя равным 0 или 1\n",
    "        в зависимости от интенсивности пикселя в объекте из данных.\n",
    "        Такой прием  называется динамическая бинаризация, он эффективно расширяет обучающую выборку и приводит к лучшим значениям \n",
    "        правдоподобия обученных моделей.\n",
    "        \"\"\"\n",
    "        batch = np.random.rand(*batch.shape) <= batch\n",
    "        train_elbo += train(batch)\n",
    "        train_batches += 1\n",
    "        \n",
    "    test_elbo = 0\n",
    "    test_batches = 0\n",
    "    for batch in iterate_minibatches(X_test, batchsize=BATCH_SIZE):\n",
    "        batch = np.random.rand(*batch.shape) <= batch\n",
    "        test_elbo += elbo_at_test(batch)\n",
    "        test_batches += 1\n",
    "        \n",
    "    print(\"Epoch {} of {} took {:.3f}s\".format(\n",
    "          epoch + 1, num_epochs, time.time() - start_time))\n",
    "    print(\"Train error {}\".format(train_elbo/train_batches))\n",
    "    print(\"Test error {}\".format(test_elbo/test_batches))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Что получается? Визуализации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import plot_reconstructions, plot_hidden_space\n",
    "\n",
    "reconstruct = theano.function(\n",
    "        [input_x],\n",
    "        T.nnet.sigmoid(lasagne.layers.get_output(decoder_logits))\n",
    ")\n",
    "\n",
    "encode = theano.function(\n",
    "        [input_x],\n",
    "        qz_x.sample(),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Визуализируем среднее распределения $p(x | z)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_reconstructions(X_test, reconstruct)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Чем отличается пространство представлений автокоидровщика от пространства представлений вариационного автокоидровщика? Почему возникло различие?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_hidden_space(X_test[:1000], encode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# рисуем по 25 сэмплов кода для каждого объекта\n",
    "x_test_repeated = np.repeat(X_test[:25], repeats=25, axis=0)\n",
    "plot_hidden_space(x_test_repeated, encode)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
